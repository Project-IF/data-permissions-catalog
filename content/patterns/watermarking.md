---
title: Watermarking

category: Understanding and influencing decisions

weight: 3

archived: false

archive_reason:

future_pattern: false

future_pattern_reason:

images:
 - url: /images/watermarking.svg
alt: An image similar to a watermark on a bank note.

advantages:
 - May provide protection from bad actors creating harmful or misleading content.
 - Helps establish authenticity.
 - Visually discreet so as not to interfere with the content itself.
 - It can be both human and machine readable.


limitations:
- The level of confidence in the accuracy of a watermark will vary by context, for example confidence will be higher on content generated with AI tools within a platform and lower for externally-generated content.
- Watermarking may depend on creators voluntarily revealing the processes behind their work.
- Watermarks can be visually removed in editing processes.
- Other needs for information about content - for example to identify political advertising, or to explain to users why they are seeing a piece of content - creates contesting demands for limited screen space.
- It does not allow users to contest the decision to use AI.
- Over time, will watermarks be ignored by people?


examples:
  - title: DeepMind's SynthID
    url: https://deepmind.google/discover/blog/identifying-ai-generated-images-with-synthid/
    description: Watermarking for images generated by AI that are imperceptible to the human eye.

---

Make it clear whether an AI system is in use to create all of, or part of, the interface or experience so that a person can make the right decisions for them. This pattern is important where the information or interface given has a material impact on the person’s choices. This is context specific.

Besides stating it plainly, other common indicators an AI system is in use include a “glow” or a sparkle icon.

IF thinks this pattern will become more important as organisations use more AI systems, and uncover the tacit user needs of making different choices depending on whether an AI is present or not.
